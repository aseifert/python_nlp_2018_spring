{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging lab\n",
    "\n",
    "## Implementing the Viterbi algorithm\n",
    "\n",
    "\n",
    "### Summary\n",
    "_(See the lecture notes for a detailed explanation of the algorithm)_\n",
    "\n",
    "The Markov assumption:\n",
    "$$\n",
    "\\mathbb{P}(w_1, w_2, \\ldots w_n \\ | \\ l_1, l_2 \\ldots l_n) =\n",
    "    \\prod_{i=1}^n\\mathbb{P}(l_i \\ | l_{i-1})\\cdot\\mathbb{P}(w_i \\ | \\ l_i)\n",
    "$$\n",
    "\n",
    "The Viterbi function determines the optimal label:\n",
    "$$\n",
    "V(w_1, w_2, \\ldots w_n) =\n",
    "{\\max}_{l_i\\in L}\n",
    "    \\prod_{i=1}^n\\mathbb{P}(l_i \\ | l_{i-1})\\cdot\\mathbb{P}(w_i \\ | \\ l_i)\n",
    "$$\n",
    "For small $n$-s:\n",
    "$$\n",
    "V(w_1) = {\\max}_{l_1\\in L} \\mathbb{P}(w_1 \\ | \\ l_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "V(w_1, w_2) = {\\max}_{l_1, l_2\\in L} \\mathbb{P}(w_1 \\ | \\ l_1) \\cdot \\mathbb{P}(l_2 \\ | \\ l_1) \\cdot \\mathbb{P}(w_2 \\ | \\ l_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "V(w_1, w_2, w_3) = {\\max}_{l_1, l_2, l_3\\in L} V(w_1, w_2) \\cdot \\mathbb{P}(l_3 \\ | \\ l_2) \\cdot \\mathbb{P}(w_3 \\ | \\ l_3)\n",
    "$$\n",
    "\n",
    "$$\n",
    "V(w_1, w_2, w_3, w_4) = {\\max}_{l_1, l_2, l_3, l_4\\in L} V(w_1, w_2, w_3) \\cdot \\mathbb{P}(l_4 \\ | \\ l_3) \\cdot \\mathbb{P}(w_4 \\ | \\ l_4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1a\n",
    "Implement a generator function that reads a tab-separated corpus file and yields tuples of (word, label).\n",
    "The file contains one token per line, in the following format:\n",
    "\n",
    "`word TAB pos-tag`\n",
    "\n",
    "_The file may contain a few malformed lines, use exception handling to print warnings and skip these lines._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b\n",
    "Download the file [`umbc.casesensitive.word_pos.1M.txt`](http://sandbox.hlt.bme.hu/~gaebor/ea_anyag/python_nlp)\n",
    "and use the generator to iterate through sentences, building a vocabulary of words and labels.\n",
    "You'll have to build:\n",
    "* a dict of words to indices\n",
    "* a dict of labels to indices\n",
    "* two reverse dicts: indices to words and indices to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2a\n",
    "Now read through the data again and build two matrices:\n",
    "* a $|V|\\times |L|$ matrix of integers\n",
    "  $$M(i,j) = \\# \\ i^\\text{th} \\text{ word with pos tag } j$$\n",
    "* an $|L|\\times |L|$ matrix of integers\n",
    "  $$N(i,j) = \\# \\ i^\\text{th} \\text{ pos after } j^\\text{th} \\text { pos}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b\n",
    "\n",
    "Compute the empirical probabilities\n",
    "* a $|V|\\times |L|$ matrix of floats\n",
    "  $$P_1(i,j) = \\frac{\\# \\ i^\\text{th} \\text{ word with pos tag } j}{\\# \\ \\text{pos tag } j}$$\n",
    "* an $|L|\\times |L|$ matrix of floats\n",
    "  $$P_2(i,j) = \\frac{\\# \\ i^\\text{th} \\text{ pos after } j^\\text{th} \\text { pos}}{\\# \\ \\text{pos tag } j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a\n",
    "Implement the Viterbi-algorithm (for $k=2$) based on the pseudocode in lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b\n",
    "Add the backtracking with an extra table, which stores the argmax, not the max value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi([\"You\", \"talk\", \"the\", \"talk\", \".\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
