{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Machine Translation — Lab solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab, we will be using [Python Natural Language Toolkit](http://www.nltk.org/) (`nltk`) again to get to know the IBM models better. There are proper, open-source MT systems out there (such as [Apertium](https://www.apertium.org/index.eng.html?dir=eng-cat#translation) and [MOSES](http://www.statmt.org/moses/)); however, getting to know them would require more than 90 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure\n",
    "\n",
    "For today's exercises, you will need the docker image again. Provided you have already downloaded it last time, you can start it by:\n",
    "\n",
    "- `docker ps -a`: lists all the containers you have created. Pick the one you used last time (with any luck, there is only one)\n",
    "- `docker start <container id>`\n",
    "- `docker exec -it <container id> bash`\n",
    "\n",
    "When that's done, update your git repository:\n",
    "\n",
    "```bash\n",
    "cd /nlp/python_nlp_2017_fall/\n",
    "git pull\n",
    "```\n",
    "\n",
    "If `git pull` returns with errors, it is most likely because some of your files have changes in it (most likely the morphology or syntax notebooks, which you worked on the previous labs). You can check this with `git status`. If the culprit is the file `A.ipynb`, you can resolve this problem like so:\n",
    "\n",
    "```\n",
    "cp A.ipynb A_mine.ipynb\n",
    "git checkout A.ipynb\n",
    "```\n",
    "\n",
    "After that, `git pull` should work.\n",
    "\n",
    "And start the notebook:\n",
    "```\n",
    "jupyter notebook --port=8888 --ip=0.0.0.0 --no-browser --allow-root\n",
    "```\n",
    "\n",
    "If you started the notebook, but cannot access it in your browser, make sure `jupyter` is not running on the host system as well. If so, stop it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate\n",
    "\n",
    "The following code imports the packages and defines the functions we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import urllib\n",
    "\n",
    "import nltk\n",
    "import numpy\n",
    "\n",
    "def download_file(url, directory=''):\n",
    "    real_dir = os.path.realpath(directory)\n",
    "    if not os.path.isdir(real_dir):\n",
    "        os.makedirs(real_dir)\n",
    "\n",
    "    file_name = url.rsplit('/', 1)[-1]\n",
    "    real_file = os.path.join(real_dir, file_name)\n",
    "    \n",
    "    if not os.path.isfile(real_file):\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            with open(real_file, 'wb') as outf:\n",
    "                shutil.copyfileobj(inf, outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Corpus acquisition\n",
    "\n",
    "We download and preprocess a subset of the [Hunglish corpus](http://mokk.bme.hu/resources/hunglishcorpus/). It consists of English-Hungarian translation pairs extracted from open-source software documentation. The sentences are already aligned, but it lacks word alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download\n",
    "\n",
    "Download the corpus. The url is `ftp://ftp.mokk.bme.hu/Hunglish2/softwaredocs/bi/opensource_X.bi`, where `X` is a number that ranges from 1 to 9. Use the `download_file` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    download_file('ftp://ftp.mokk.bme.hu/Hunglish2/softwaredocs/bi/opensource_{}.bi'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Conversion\n",
    "\n",
    "Read the whole corpus (all files), but do not read it all into memory. Write a function that\n",
    "\n",
    "- reads all files you have just downloaded\n",
    "- is a generator that yields tuples (Hungarian snippet, English snippet)\n",
    "\n",
    "Note:\n",
    "- the files are encoded with the `iso-8859-2` (a.k.a. `Latin-2`) encoding\n",
    "- the Hungarian and English snippets are separated by a tab\n",
    "- don't forget to strip whitespace from the returned snippets\n",
    "- throw away pairs with empty snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(directory=''):\n",
    "    for i in range(1, 10):\n",
    "        with open(os.path.join(directory, 'opensource_{}.bi'.format(i)), encoding='iso-8859-2') as inf:\n",
    "            for line in inf:\n",
    "                snippets = tuple(map(str.strip, line.split('\\t')))\n",
    "                if len(snippets[0]) and len(snippets[1]):\n",
    "                   yield snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Tokenization\n",
    "\n",
    "The text is not tokenized. Use `nltk`'s `word_tokenize()` function to tokenize the snippets. Also, lowercase them. You can do this in `read_files()` above if you wish, or in the code you write for [1.4](#1.4-Create-the-training-corpus) below.\n",
    "\n",
    "Note:\n",
    "- The model for the sentence tokenizer (`punkt`) is not installed by default. You have to `download()` it.\n",
    "- NLTK doesn't have Hungarian tokenizer models, so there might be errors in the Hungarian result\n",
    "- instead of just lowercasing everything, we might have chosen a more sophisticated solution, e.g. by first calling `sent_tokenize()` and then just lowercase the word at the beginning of the sentence, or even better, tag the snippets for NER. However, we have neither the time nor the resources (models) to do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def preprocess(snippets):\n",
    "    for hu_snippet, en_snippet in snippets:\n",
    "        yield (list(map(str.lower, word_tokenize(hu_snippet))),\n",
    "               list(map(str.lower, word_tokenize(en_snippet))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Create the training corpus\n",
    "\n",
    "The models we are going to expect a list of [`nltk.translate.api.AlignedSent`](http://www.nltk.org/api/nltk.translate.html) objects. Create a `bitext` variable that is a list of `AlignedSent` objects created from the preprocessed, tokenized corpus.\n",
    "\n",
    "Note that `AlignedSent` also allows you to specify an *alignment* between the words in the two texts. Unfortunately (but not unexpectedly), the corpus doesn't have this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.api import AlignedSent\n",
    "bitext = [AlignedSent(*t) for t in preprocess(read_files())]\n",
    "\n",
    "assert len(bitext) == 135439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a few sentences from the corpus. Play around with the indices until you find another 3 interesting sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bitext[100])\n",
    "display(bitext[100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. IBM Models\n",
    "\n",
    "NLTK implements IBM models 1-5. Unfortunately, the implementations don't provide the end-to-end machine translation systems, only their alignment models. Also, as you will see, the API leaves a lot to desired $-$ it will be your task to smoothen the rought edges. However, if you complete exercise 2, you will have a working IBM Model 1 system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 IBM Model 1\n",
    "\n",
    "Train an [IBM Model 1](http://www.nltk.org/api/nltk.translate.html#module-nltk.translate.ibm1) alignment. We do it in a separate code block, so that we don't rerun it by accident – training even a simple model takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import IBMModel1\n",
    "ibm1 = IBMModel1(bitext, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IBM models learn the **inverse translation probability**, so\n",
    "- the **source** sentence is the second one in `AlignedSent` (here: English)\n",
    "- the **target** sentence is the first one in `AlignedSent` (here: Hungarian).\n",
    "\n",
    "In effect, our `ibm1` object learned an English-to-Hungarian translation model.\n",
    "\n",
    "The model has two outputs:\n",
    "1. The main output of the model is the _translation table_ (`ibm1.translation_table`), which stores the (word-to-word) translation probabilities\n",
    "1. It also assignes an alignment to each `AlignedSent` object in the input corpus.\n",
    "\n",
    "To see the [`Alignment`](http://www.nltk.org/api/nltk.translate.html#nltk.translate.api.Alignment)s, display the sentences you have chosen above again in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alignment in text:', bitext[100].alignment)\n",
    "display(bitext[100])\n",
    "display(bitext[100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other output is the word-to-word translation table. Unfortunately, it is not structured in a very well thought-out way. Even though it represents $P(t|s)$ word translation probabilities, the table is structured as\n",
    "\n",
    "```Python\n",
    "ibm1.translation_table[target_word][source_word] == probability\n",
    "```\n",
    "\n",
    "In other words, it is easy to get the list of source words that translate to a target word, but it is very inefficient to enumerate all target words a source word can translate to, as one has to enumerate all entries of the form `ibm1.translation_table[*][source_word]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Inverse translation table\n",
    "\n",
    "In this exercise, we are going to fix this issue by creating another table that can be indexed by source first. Write a function that adds a new field `source_target_table` to `ibm1`, where $\\forall s,t:$ `ibm1.source_target_table[s][t] == ibm1.translation_table[t][s]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverse_table(model):\n",
    "    d = dict()\n",
    "    for t, sd in model.translation_table.items():\n",
    "        for s, p in sd.items():\n",
    "            d.setdefault(s, {})[t] = p\n",
    "    model.source_target_table = d\n",
    "    \n",
    "# Let's test it\n",
    "create_inverse_table(ibm1)\n",
    "\n",
    "for t in random.sample(ibm1.trg_vocab, 1000):\n",
    "    # Cannot sample ibm1.src_vocab, because the table is sparse\n",
    "    s, p = random.choice(list(ibm1.translation_table[t].items()))\n",
    "    assert ibm1.translation_table[t][s] == ibm1.source_target_table[s][t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Most probable word translations\n",
    "\n",
    "With our new table, we can query word translation probabilities efficiently. Write a function that has three arguments:\n",
    "- `word` is a word\n",
    "- `source` is a boolean; the default is `True`\n",
    "- `k` is the number of translations to return; the default is 5.\n",
    "\n",
    "The function returns the most probable $k$ target words `word` translates to if `source` is `True`; otherwise, it returns the $k$ source words most likely to translate to the target `word`. In other words, `word` can both be source and target word depending on the second parameter.\n",
    "\n",
    "The function should return a list of `(word, probability)` tuples. If the word is not found in the model, return an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_probable_words(word, source=True, k=5):\n",
    "    if source:\n",
    "        translations = ibm1.source_target_table.get(word, {})\n",
    "    else:\n",
    "        translations = ibm1.translation_table.get(word, {})\n",
    "    translations = {k: v for k, v in translations.items() if k and v}\n",
    "    return sorted(translations.items(), key=lambda kv: (-kv[1], kv[0]))[:k]\n",
    "\n",
    "assert most_probable_words('home') == most_probable_words('home', True) == most_probable_words('home', True, 5)\n",
    "assert [w for w, _ in most_probable_words('home', k=4)] == ['saját', 'otthoni', 'kezdőlap', 'honlap']\n",
    "assert len(most_probable_words('otthoni')) == 0\n",
    "assert len(most_probable_words('signature', k=1000)) == 481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More about the IBM Model 1...\n",
    "\n",
    "While the model doesn't have a `translate()` function, it does provide a way to compute the **translation probability** $P(T|S)$ with some additional codework. That additional work is what you have to put in.\n",
    "\n",
    "As a reminder, here are the formulas for computing the translation probability. Following `IBMModel1`, instead of the $F$ (_foreign_) and $E$ (_English_) in the lecture, we are going to use $T$ for the _target_ and $S$ for the _source_ languages.\n",
    "\n",
    "The formulas of the translation probability is $P(T|S) = \\sum_A P(T,A|S)$,<br>\n",
    "where $P(T,A|S) = P(T|S,A) \\times P(A|S)$.\n",
    "\n",
    "The right side is computed as:\n",
    "- alignment probability: $P(A|S) = \\frac{\\epsilon}{(J + 1)^K}$, where $J$ and $K$ are the lengths of the source and target sentences, respectively;\n",
    "- probability of the source sentence given $A$: $P(T|S,A) = \\prod_{k=1}^KP(t_k|s_{a_k})$, where $s_{a_k}$ is the source word that the alignment $A$ maps to the target word $t_k$.\n",
    "\n",
    "The functions available in `IBMModel1` of interest to us are:\n",
    "- `prob_alignment_point(s, t)`: $P(t|s)$.\n",
    "- `prob_t_a_given_s(alignment_info)`: it claims to be $P(T,A|S)$, but actually it computes $P(T|S,A)$.\n",
    "\n",
    "Of the two functions, we will need the second one, which will invoke the former to compute $P(T|S,A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Alignment conversion\n",
    "\n",
    "There is a slight problem with `prob_t_a_given_s()`: instead of an [`AlignedSent`](http://www.nltk.org/api/nltk.translate.html) (which we already have at this point), it expects an [`AlignmentInfo`](http://www.nltk.org/api/nltk.translate.html#nltk.translate.ibm_model.AlignmentInfo) object that contains about the same information: the source and target sentences as well as the aligment between them.\n",
    "\n",
    "Unfortunately, `AlignmentInfo`'s representation of an alignment is completely different from the [`Alignment`](http://www.nltk.org/api/nltk.translate.html#nltk.translate.api.Alignment) object's. In a nutshell, given the 100th sentence displayed below,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alignment:', bitext[100].alignment)\n",
    "display(bitext[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Alignments:\n",
    "      - `Aligment` in `AlignedSent` is a list of 0-based index pairs, `[(0, 4), (1, 0), (2, 1), (3, 0)]`\n",
    "      - Don't forget that the IBM model translates from the second to the first sentence, so this in effect is a **target-to-source** alignment\n",
    "      - The alignment in the `AlignmentInfo` objects is a `tuple` (!), where the `i`th position is the index of the source word that is aligned to the `i`th target word $-$ or `0`, if the `i`th target word is unaligned. The indices are **1-based**, because the `0`the word is `NULL` on both sides (see lecture page 35, slide 82). The tuple must also make space for the (unused)  alignment for this `NULL` word. So the alignment for our sentence is `(0, 5, 1, 2, 1)` (e.g. the 3rd word, _otthoni_ in the target sentence is aligned with the 2nd source word, _home_, so `alignment[3] == 2`).\n",
    "  - Sentences:\n",
    "      - The sentences in `AlignedSent` are just list of words\n",
    "      - Th sentences in `AlignmentInfo` are tuples of words, and they both contain an extra `None` as the 0th item to account for the `NULL` element, above.\n",
    "  \n",
    "Your first is task to do the conversion from `AlignedSet` to `AlignmentInfo`. Take extra care not to mix up the source and target languages! In the constructor, leave _cepts_ empty.\n",
    "\n",
    "**Note**: you can find test cases for tasks 2.4 $-$ 2.7 [at the end of the exercise](#Test-cases-for-Exercises-2.5-%E2%80%93-2.7.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.ibm_model import AlignmentInfo\n",
    "\n",
    "def alignment_to_info(aligned_sent):\n",
    "    source_sent = tuple([None] + aligned_sent.mots)\n",
    "    target_sent = tuple([None] + aligned_sent.words)\n",
    "    alignment = [0 for _ in range(len(target_sent))]\n",
    "    for t, s in dict(aligned_sent.alignment).items():\n",
    "        alignment[t + 1] = s + 1\n",
    "    return AlignmentInfo(tuple(alignment), source_sent, target_sent, None)\n",
    "\n",
    "ai_100 = alignment_to_info(bitext[100])\n",
    "ai_100k = alignment_to_info(bitext[100000])\n",
    "\n",
    "assert ai_100.alignment == (0, 5, 1, 2, 1)\n",
    "assert ai_100.src_sentence == (None, 'groupwise', 'home', 'screen', 'name', '1')\n",
    "\n",
    "assert ai_100k.alignment == (0, 1, 3, 2, 4)\n",
    "assert ai_100k.trg_sentence == (None, 'nem', 'található', 'aláírás', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with the `AlignmentInfo` objects, we can compute $P(T|S,A)$ for the most probable alignments (those stored in the `AlignedSent` objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm1.prob_t_a_given_s(ai_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Compute $P(T,A|S)$\n",
    "\n",
    "As a reminder, $P(T,A|S) = P(T|A,S) \\times P(A|S)$.\n",
    "\n",
    "Since `prob_t_a_given_s()` only computes $P(T|A,S)$, you have to add the $P(A|S)$ component. See page 38, slide 95 and page 39, side 100 in the lecture (don't forget that the notation is different: $S \\equiv E$ and $T \\equiv F$). Treat $\\epsilon$ as 1.\n",
    "\n",
    "The function should take the `model` and an `AlignmentInfo` as parameters. Don't forget that the sentences in `AlignmentInfo` contain an extra \"word\" when computing their lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_prob_t_a_given_s(model, alignment_info):\n",
    "    return model.prob_t_a_given_s(alignment_info) / pow(\n",
    "        len(alignment_info.src_sentence), len(alignment_info.trg_sentence) - 1)\n",
    "\n",
    "assert real_prob_t_a_given_s(ibm1, ai_100) == ibm1.prob_t_a_given_s(ai_100) / 1296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Compute $P(F, A_{best}|E)$\n",
    "\n",
    "Using the function you just implemented, write another one that, given an `AlignedSent` object, computes $P(T,A|S)$. Since `IBMModel1` aligns the sentences of the training set with the most probable alignment, this function will effectively compute $P(T,A_{best}|S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_t_best_a_given_s(model, aligned_sent):\n",
    "    return real_prob_t_a_given_s(model, alignment_to_info(aligned_sent))\n",
    "\n",
    "assert numpy.allclose(prob_t_best_a_given_s(ibm1, bitext[100]), real_prob_t_a_given_s(ibm1, ai_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Compute $P(T|S)$\n",
    "\n",
    "Write a function that, given an `AlignedSent` object, computes $P(T|S)$. It should enumerate all possible alignments (in the tuple format) and call the function you wrote in Exercise 2.5 with them.\n",
    "\n",
    "Note: the [`itertools.product`](https://docs.python.org/3.5/library/itertools.html#itertools.product) function can be very useful in enumerating the alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def prob_t_given_s(model, aligned_sent):\n",
    "    ali = alignment_to_info(aligned_sent)\n",
    "    p = 0\n",
    "    for alig in product(range(len(ali.src_sentence)), repeat=len(ali.trg_sentence) - 1):\n",
    "        ali.alignment = tuple([0] + list(alig))\n",
    "        p += real_prob_t_a_given_s(model, ali)\n",
    "    return p\n",
    "        \n",
    "prob_t_given_s(ibm1, bitext[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test cases for Exercises 2.5 – 2.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testext = [\n",
    "    AlignedSent(['klein', 'ist', 'das', 'haus'], ['the', 'house', 'is', 'small']),\n",
    "    AlignedSent(['das', 'haus', 'ist', 'ja', 'groß'], ['the', 'house', 'is', 'big']),\n",
    "    AlignedSent(['das', 'buch', 'ist', 'ja', 'klein'], ['the', 'book', 'is', 'small']),\n",
    "    AlignedSent(['das', 'haus'], ['the', 'house']),\n",
    "    AlignedSent(['das', 'buch'], ['the', 'book']),\n",
    "    AlignedSent(['ein', 'buch'], ['a', 'book'])\n",
    "]\n",
    "ibm2 = IBMModel1(testext, 5)\n",
    "\n",
    "# Tests for Exercise 2.4\n",
    "testalis = [alignment_to_info(s) for s in testext]\n",
    "\n",
    "assert testalis[2].alignment == (0, 1, 2, 3, 3, 4)\n",
    "assert testalis[5].alignment == (0, 1, 2)\n",
    "\n",
    "# Tests for Exercise 2.5\n",
    "assert numpy.allclose(real_prob_t_a_given_s(ibm2, testalis[5]), 0.08283000979778607)\n",
    "assert numpy.allclose(real_prob_t_a_given_s(ibm2, testalis[0]), 0.00018256804431244556)\n",
    "\n",
    "# Tests for Exercise 2.6\n",
    "assert numpy.allclose(prob_t_best_a_given_s(ibm2, testext[4]), 0.059443309368677)\n",
    "assert numpy.allclose(prob_t_best_a_given_s(ibm2, testext[2]), 1.3593610057711997e-05)\n",
    "\n",
    "# Tests for Exercise 2.7\n",
    "assert numpy.allclose(prob_t_given_s(ibm2, testext[4]), 0.13718805082588842)\n",
    "assert numpy.allclose(prob_t_given_s(ibm2, testext[2]), 0.0001809283308942621)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Phrase-based translation\n",
    "\n",
    "NLTK also has some functions related to phrase-based translation, but these are all but finished. The components are scattered into two packages:\n",
    "- [phrase_based](http://www.nltk.org/api/nltk.translate.html#module-nltk.translate.phrase_based) defines the function `phrase_extraction()` that can extract phrases from parallel text, based on an alignment\n",
    "- [stack_decoder](http://www.nltk.org/api/nltk.translate.html#module-nltk.translate.stack_decoder) defines the `StackDecoder` object, which can be used to translate sentences based on a phrase table and a language model\n",
    "\n",
    "#### 3.1. Decoding example\n",
    "\n",
    "If you are wondering where the rest of the training functionality is, you spotted the problem: unfortunately, the part that assembles the phrase table based on the extracted phrases is missing. Also missing are the classes that represent and compute a language model. So in the code block below, we only run the decoder on an example sentence with a \"hand-crafted\" model.\n",
    "\n",
    "Note: This is the same code as in the documentation of the decoder (above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "from nltk.translate import PhraseTable\n",
    "from nltk.translate.stack_decoder import StackDecoder\n",
    "\n",
    "# The (probabilistic) phrase table\n",
    "phrase_table = PhraseTable()\n",
    "phrase_table.add(('niemand',), ('nobody',), log(0.8))\n",
    "phrase_table.add(('niemand',), ('no', 'one'), log(0.2))\n",
    "phrase_table.add(('erwartet',), ('expects',), log(0.8))\n",
    "phrase_table.add(('erwartet',), ('expecting',), log(0.2))\n",
    "phrase_table.add(('niemand', 'erwartet'), ('one', 'does', 'not', 'expect'), log(0.1))\n",
    "phrase_table.add(('die', 'spanische', 'inquisition'), ('the', 'spanish', 'inquisition'), log(0.8))\n",
    "phrase_table.add(('!',), ('!',), log(0.8))\n",
    "\n",
    "# The \"language model\"\n",
    "language_prob = defaultdict(lambda: -999.0)\n",
    "language_prob[('nobody',)] = log(0.5)\n",
    "language_prob[('expects',)] = log(0.4)\n",
    "language_prob[('the', 'spanish', 'inquisition')] = log(0.2)\n",
    "language_prob[('!',)] = log(0.1)\n",
    "# Note: type() with three parameters creates a new type object\n",
    "language_model = type('',(object,), {'probability_change': lambda self, context, phrase: language_prob[phrase],\n",
    "                                     'probability': lambda self, phrase: language_prob[phrase]})()\n",
    "\n",
    "stack_decoder = StackDecoder(phrase_table, language_model)\n",
    "\n",
    "stack_decoder.translate(['niemand', 'erwartet', 'die', 'spanische', 'inquisition', '!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train the phrase table*\n",
    "\n",
    "Run through the parallel corpus (already aligned by an IBM model), and extract all phrases from them. You can limit the length of the phrases you consider at 2 (3, ...) words, but you have to do it manually, because the `max_phrase_length` argument of `phrase_extraction()` doesn't work. Once you have all the phrases, create a phrase table similar to the one above. Don't forget that the decoder expects _log_ probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
